{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2rFUTX+XSZeJwVQmonc/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-srk/NLP/blob/main/SATVIK_NLP_ASSIGNMENT_02_PART_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fXXYCViG8WYW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from os import makedirs, path, remove, rename, rmdir\n",
        "from tarfile import open as open_tar\n",
        "from shutil import rmtree\n",
        "from urllib import request, parse\n",
        "from glob import glob\n",
        "from re import sub\n",
        "from email import message_from_file\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from collections import defaultdict\n",
        "from functools import partial\n",
        "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score)\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C4fIGS9-8wce"
      },
      "outputs": [],
      "source": [
        "def download_corpus(dataset_dir: str = 'data'):\n",
        "    base_url = 'https://spamassassin.apache.org'\n",
        "    corpus_path = 'old/publiccorpus'\n",
        "    files = {\n",
        "        '20021010_easy_ham.tar.bz2': 'ham',\n",
        "        '20021010_hard_ham.tar.bz2': 'ham',\n",
        "        '20021010_spam.tar.bz2': 'spam',\n",
        "        '20030228_easy_ham.tar.bz2': 'ham',\n",
        "        '20030228_easy_ham_2.tar.bz2': 'ham',\n",
        "        '20030228_hard_ham.tar.bz2': 'ham',\n",
        "        '20030228_spam.tar.bz2': 'spam',\n",
        "        '20030228_spam_2.tar.bz2': 'spam',\n",
        "        '20050311_spam_2.tar.bz2': 'spam' }\n",
        "\n",
        "    #creates the folders: downloads, ham and spam\n",
        "    downloads_dir = path.join(dataset_dir, 'downloads')\n",
        "    ham_dir = path.join(dataset_dir, 'ham')\n",
        "    spam_dir = path.join(dataset_dir, 'spam')\n",
        "\n",
        "    makedirs(downloads_dir, exist_ok=True)\n",
        "    makedirs(ham_dir, exist_ok=True)\n",
        "    makedirs(spam_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    for file, spam_or_ham in files.items():\n",
        "        # download files from URL of each specific .bz2 file\n",
        "        url = parse.urljoin(base_url, f'{corpus_path}/{file}')\n",
        "        tar_filename = path.join(downloads_dir, file)\n",
        "        request.urlretrieve(url, tar_filename)\n",
        "\n",
        "        #list e-mails in the compressed .bz2 file\n",
        "        emails = []\n",
        "        with open_tar(tar_filename) as tar:\n",
        "            tar.extractall(path=downloads_dir)\n",
        "            for tarinfo in tar:\n",
        "                if len(tarinfo.name.split('/')) > 1:\n",
        "                    emails.append(tarinfo.name)\n",
        "\n",
        "        # move e-mails to ham or spam directory\n",
        "        for email in emails:\n",
        "            directory, filename = email.split('/')\n",
        "            directory = path.join(downloads_dir, directory)\n",
        "\n",
        "            if not path.exists(path.join(dataset_dir, spam_or_ham, filename)):\n",
        "                rename(path.join(directory, filename),\n",
        "                   path.join(dataset_dir, spam_or_ham, filename))\n",
        "\n",
        "        rmtree(directory)\n",
        "\n",
        "download_corpus()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many e-mails are classified in our dataset as either Spam or not Spam?\n",
        "ham_dir = path.join('data', 'ham')\n",
        "spam_dir = path.join('data', 'spam')\n",
        "\n",
        "print('Number of Non-Spam E-mails:', len(glob(f'{ham_dir}/*')))\n",
        "print('\\nNumber of Spam E-mails:', len(glob(f'{spam_dir}/*')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS5JFGGr8qy5",
        "outputId": "ae73ccbc-04ab-4740-e896-f40a24c5e374"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Non-Spam E-mails: 6952\n",
            "\n",
            "Number of Spam E-mails: 2399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### START CODE ####\n",
        "\n",
        "# Read emails into a dataframe\n",
        "def read_emails(directory, label):\n",
        "    emails = []\n",
        "    for filepath in glob(f\"{directory}/*\"):\n",
        "        with open(filepath, 'r', errors='ignore') as file:\n",
        "            emails.append(file.read())\n",
        "    return pd.DataFrame({'text': emails, 'label': label})\n",
        "\n",
        "ham_emails = read_emails(ham_dir, 'ham')\n",
        "spam_emails = read_emails(spam_dir, 'spam')\n",
        "\n",
        "# Combine ham and spam into a single dataframe\n",
        "all_emails = pd.concat([ham_emails, spam_emails], ignore_index=True)\n",
        "\n",
        "# Vectorize the email text data\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(all_emails['text'])\n",
        "y = all_emails['label'].apply(lambda x: 1 if x == 'spam' else 0)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_index, test_index = next(sss.split(X, y))\n",
        "X_train, X_test = X[train_index], X[test_index]\n",
        "y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "# Train a Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "#### END CODE ####"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_2OtfFP_wti",
        "outputId": "907a353c-1ccb-4d6d-eac5-8a067950b7bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9754\n",
            "Precision: 0.9697\n",
            "Recall: 0.9333\n",
            "F1 Score: 0.9512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to classify a single email\n",
        "def classify_email(email_text):\n",
        "    email_vector = vectorizer.transform([email_text])\n",
        "    prediction = nb_classifier.predict(email_vector)\n",
        "    return 'spam' if prediction[0] == 1 else 'ham'\n",
        "\n",
        "# Test case with provided spam email\n",
        "spam_email = \"\"\"\n",
        "Subject: Get Rich Quick!\n",
        "\n",
        "Dear Friend,\n",
        "\n",
        "Congratulations! You've been selected to participate in an exclusive opportunity to make thousands of dollars from the comfort of your own home. Our revolutionary system guarantees quick and easy cash with minimal effort.\n",
        "\n",
        "No more struggling to pay bills or worrying about financial security. With our proven method, you can start earning massive amounts of money in no time.\n",
        "\n",
        "Here's what some of our satisfied customers have to say:\n",
        "- \"I was skeptical at first, but I'm now living my dream life thanks to this incredible system!\" - John S.\n",
        "- \"I never thought making money online could be this simple. It's changed my life!\" - Sarah L.\n",
        "\n",
        "Don't miss out on this limited-time offer. Act now to secure your spot and start enjoying a life of financial freedom.\n",
        "\n",
        "Click the link below to get started:\n",
        "www.getrichquick.com\n",
        "\n",
        "Remember, this opportunity is exclusive and won't last long. Take control of your financial future today!\n",
        "\n",
        "Best regards,\n",
        "The Get Rich Quick Team\n",
        "\"\"\"\n",
        "\n",
        "classification = classify_email(spam_email)\n",
        "print(f\"The provided email is classified as: {classification}\")"
      ],
      "metadata": {
        "id": "_lvIjkRW_O8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15dab468-c54b-48c7-9375-801fb452d179"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided email is classified as: spam\n"
          ]
        }
      ]
    }
  ]
}